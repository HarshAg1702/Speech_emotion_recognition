{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HarshAg1702/Speech_emotion_recognition/blob/main/emotion_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "url = \"https://www.kaggle.com/api/v1/datasets/download/uwrfkaggler/ravdess-emotional-speech-audio?datasetVersionNumber=1\"\n",
        "\n",
        "response = requests.get(url)\n",
        "zip_path = \"/content/ravdess.zip\"\n",
        "\n",
        "# Write the content to a file\n",
        "with open(zip_path, \"wb\") as file:\n",
        "    file.write(response.content)\n",
        "\n",
        "# Extract the ZIP file\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(\"/content/ravdess\")\n",
        "\n",
        "# Path to the extracted dataset\n",
        "RAVDESS = \"/content/ravdess\"\n",
        "\n",
        "os.remove(zip_path)\n",
        "\n",
        "path_to_delete = \"/content/ravdess/audio_speech_actors_01-24\"\n",
        "\n",
        "if os.path.exists(path_to_delete):\n",
        "    shutil.rmtree(path_to_delete)\n",
        "else:\n",
        "    print(f\"Path does not exist: {path_to_delete}\")"
      ],
      "metadata": {
        "id": "OEcr7PQiKlr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Paths to the directories\n",
        "train_set_path = os.path.join(RAVDESS, \"Train Set\")\n",
        "test_set_path = os.path.join(RAVDESS, \"Test Set\")\n",
        "\n",
        "# Create the subfolders if they don't exist\n",
        "os.makedirs(train_set_path, exist_ok=True)\n",
        "os.makedirs(test_set_path, exist_ok=True)\n",
        "\n",
        "# List of actor folders in the RAVDESS directory\n",
        "actor_folders = sorted([f for f in os.listdir(RAVDESS) if f.startswith(\"Actor_\")])\n",
        "\n",
        "for actor in actor_folders[0:20]:\n",
        "    shutil.move(os.path.join(RAVDESS, actor), train_set_path)\n",
        "\n",
        "for actor in actor_folders[20:24]:\n",
        "    shutil.move(os.path.join(RAVDESS, actor), test_set_path)"
      ],
      "metadata": {
        "id": "wz6X9W6UloJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Filename identifiers as per the official RAVDESS website:**\n",
        "\n",
        "Modality (01 = full-AV, 02 = video-only, 03 = audio-only).\n",
        "\n",
        "Vocal channel (01 = speech, 02 = song).\n",
        "\n",
        "Emotion (01 = neutral, 02 = calm, 03 = happy, 04 = sad, 05 = angry, 06 =\n",
        "fearful, 07 = disgust, 08 = surprised).\n",
        "\n",
        "Emotional intensity (01 = normal, 02 = strong). NOTE: There is no strong intensity for the 'neutral' emotion.\n",
        "\n",
        "Statement (01 = \"Kids are talking by the door\", 02 = \"Dogs are sitting by the door\").\n",
        "\n",
        "Repetition (01 = 1st repetition, 02 = 2nd repetition).\n",
        "Actor (01 to 24. Odd numbered actors are male, even numbered actors are female).\n",
        "\n",
        "## Example:\n",
        "\n",
        "02-01-06-01-02-01-12.mp4\n",
        "\n",
        "This means the meta data for the audio file is:\n",
        "\n",
        "Video-only (02)\n",
        "\n",
        "Speech (01)\n",
        "\n",
        "Fearful (06)\n",
        "\n",
        "Normal intensity (01)\n",
        "\n",
        "Statement \"dogs\" (02)\n",
        "\n",
        "1st Repetition (01)\n",
        "\n",
        "12th Actor (12) - Female (as the actor ID number is even)"
      ],
      "metadata": {
        "id": "S2QkByRXe4pL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = {\n",
        "  '01':'neutral',\n",
        "  '02':'calm',\n",
        "  '03':'happy',\n",
        "  '04':'sad',\n",
        "  '05':'angry',\n",
        "  '06':'fearful',\n",
        "  '07':'disgust',\n",
        "  '08':'surprised'\n",
        "}\n",
        "\n",
        "observed_emotions = ['happy', 'sad', 'angry', 'fearful', 'neutral']"
      ],
      "metadata": {
        "id": "xPp3spe4sJxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9e5K34qJOVh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "from glob import glob\n",
        "from IPython.display import Audio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_set_list = os.listdir(train_set_path)\n",
        "\n",
        "data = []\n",
        "\n",
        "for dir in train_set_list:\n",
        "  actor = os.listdir(train_set_path+ '/'+ dir)\n",
        "  for file in actor:\n",
        "    part = file.split('.')[0]\n",
        "    part = part.split('-')\n",
        "    emotion = emotions.get(part[2], None)\n",
        "    if emotion is not None and emotion in observed_emotions:\n",
        "      file_path = os.path.join(train_set_path, dir, file)\n",
        "      data.append({'Emotion': emotion, 'File_Path': file_path})\n",
        "\n",
        "ravdess_df = pd.DataFrame(data)\n",
        "print(ravdess_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QY2e8EY_jod9",
        "outputId": "a43b0ed1-cc03-451d-d9bd-8a08202def2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     Emotion                                          File_Path\n",
            "0        sad  /content/ravdess/Train Set/Actor_08/03-01-04-0...\n",
            "1    fearful  /content/ravdess/Train Set/Actor_08/03-01-06-0...\n",
            "2    fearful  /content/ravdess/Train Set/Actor_08/03-01-06-0...\n",
            "3    neutral  /content/ravdess/Train Set/Actor_08/03-01-01-0...\n",
            "4      angry  /content/ravdess/Train Set/Actor_08/03-01-05-0...\n",
            "..       ...                                                ...\n",
            "715    angry  /content/ravdess/Train Set/Actor_11/03-01-05-0...\n",
            "716    happy  /content/ravdess/Train Set/Actor_11/03-01-03-0...\n",
            "717  fearful  /content/ravdess/Train Set/Actor_11/03-01-06-0...\n",
            "718  neutral  /content/ravdess/Train Set/Actor_11/03-01-01-0...\n",
            "719    angry  /content/ravdess/Train Set/Actor_11/03-01-05-0...\n",
            "\n",
            "[720 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import soundfile as sf\n",
        "\n",
        "# Constants\n",
        "NOISE_FACTOR = 0.035\n",
        "SHIFT_MAX = 0.5\n",
        "PITCH_STEPS = 2\n",
        "SPEED_FACTOR = 1.5\n",
        "\n",
        "# Function to add noise to a signal\n",
        "def add_noise(data, noise_factor=NOISE_FACTOR):\n",
        "    noise = np.random.randn(len(data))\n",
        "    augmented_data = data + noise_factor * noise\n",
        "    return augmented_data\n",
        "\n",
        "# Function to shift a signal in time\n",
        "def shift_time(data, shift_max=SHIFT_MAX):\n",
        "    shift = np.random.randint(int(len(data) * shift_max))\n",
        "    augmented_data = np.roll(data, shift)\n",
        "    return augmented_data\n",
        "\n",
        "# Function to change the pitch of a signal\n",
        "def change_pitch(data, sampling_rate, pitch_steps=PITCH_STEPS):\n",
        "    return librosa.effects.pitch_shift(data, sr=sampling_rate, n_steps=pitch_steps)\n",
        "\n",
        "# Function to change the speed of a signal\n",
        "def change_speed(data, speed_factor=SPEED_FACTOR):\n",
        "    return librosa.effects.time_stretch(data, rate=speed_factor)\n",
        "\n",
        "# Apply data augmentation\n",
        "augmented_data = []\n",
        "\n",
        "for index, row in ravdess_df.iterrows():\n",
        "    y, sr = librosa.load(row['File_Path'])\n",
        "\n",
        "    # Apply noise injection\n",
        "    noisy_data = add_noise(y)\n",
        "    noisy_file_path = row['File_Path'].replace(\".wav\", \"_noisy.wav\")\n",
        "    sf.write(noisy_file_path, noisy_data, sr)\n",
        "    augmented_data.append({'Emotion': row['Emotion'], 'File_Path': noisy_file_path})\n",
        "\n",
        "    # Apply time shifting\n",
        "    shifted_data = shift_time(y)\n",
        "    shifted_file_path = row['File_Path'].replace(\".wav\", \"_shifted.wav\")\n",
        "    sf.write(shifted_file_path, shifted_data, sr)\n",
        "    augmented_data.append({'Emotion': row['Emotion'], 'File_Path': shifted_file_path})\n",
        "\n",
        "    # Apply pitch shifting\n",
        "    pitched_data = change_pitch(y, sr)\n",
        "    pitched_file_path = row['File_Path'].replace(\".wav\", \"_pitched.wav\")\n",
        "    sf.write(pitched_file_path, pitched_data, sr)\n",
        "    augmented_data.append({'Emotion': row['Emotion'], 'File_Path': pitched_file_path})\n",
        "\n",
        "    # Apply speed change\n",
        "    try:\n",
        "        speed_data = change_speed(y, SPEED_FACTOR)\n",
        "        speed_file_path = row['File_Path'].replace(\".wav\", \"_speed.wav\")\n",
        "        sf.write(speed_file_path, speed_data, sr)\n",
        "        augmented_data.append({'Emotion': row['Emotion'], 'File_Path': speed_file_path})\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing file {row['File_Path']} with speed factor {SPEED_FACTOR}: {e}\")\n",
        "\n",
        "augmented_df = pd.DataFrame(augmented_data)\n",
        "final_df = pd.concat([ravdess_df, augmented_df], ignore_index=True)\n",
        "\n",
        "print(final_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cnWiOtSsOIY",
        "outputId": "b3f0ad8b-979a-4444-c034-67fc45edac90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Emotion                                          File_Path\n",
            "0         sad  /content/ravdess/Train Set/Actor_08/03-01-04-0...\n",
            "1     fearful  /content/ravdess/Train Set/Actor_08/03-01-06-0...\n",
            "2     fearful  /content/ravdess/Train Set/Actor_08/03-01-06-0...\n",
            "3     neutral  /content/ravdess/Train Set/Actor_08/03-01-01-0...\n",
            "4       angry  /content/ravdess/Train Set/Actor_08/03-01-05-0...\n",
            "...       ...                                                ...\n",
            "3595  neutral  /content/ravdess/Train Set/Actor_11/03-01-01-0...\n",
            "3596    angry  /content/ravdess/Train Set/Actor_11/03-01-05-0...\n",
            "3597    angry  /content/ravdess/Train Set/Actor_11/03-01-05-0...\n",
            "3598    angry  /content/ravdess/Train Set/Actor_11/03-01-05-0...\n",
            "3599    angry  /content/ravdess/Train Set/Actor_11/03-01-05-0...\n",
            "\n",
            "[3600 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract features from an audio file\n",
        "def extract_features(file_path):\n",
        "    y, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    # Extract MFCCs\n",
        "    mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n",
        "    mfccs_mean = np.mean(mfccs, axis=1)\n",
        "\n",
        "    # Extract Chroma feature\n",
        "    chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
        "    chroma_mean = np.mean(chroma, axis=1)\n",
        "\n",
        "    # Extract Spectral Contrast\n",
        "    spectral_contrast = librosa.feature.spectral_contrast(y=y, sr=sr)\n",
        "    spectral_contrast_mean = np.mean(spectral_contrast, axis=1)\n",
        "\n",
        "    # Extract Zero Crossing Rate\n",
        "    zero_crossing_rate = librosa.feature.zero_crossing_rate(y)\n",
        "    zero_crossing_rate_mean = np.mean(zero_crossing_rate)\n",
        "\n",
        "    # Extract Root Mean Square Energy\n",
        "    S = np.abs(librosa.stft(y))\n",
        "    rmse = librosa.feature.rms(S=S)\n",
        "    rmse_mean = np.mean(rmse)\n",
        "\n",
        "    # Extract Mel-spectrogram\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128)\n",
        "    mel_spectrogram_mean = np.mean(mel_spectrogram, axis=1)\n",
        "\n",
        "    # Concatenate all features\n",
        "    features = np.hstack((mfccs_mean, chroma_mean, spectral_contrast_mean, zero_crossing_rate_mean, rmse_mean, mel_spectrogram_mean))\n",
        "\n",
        "    return features\n",
        "\n",
        "# Extract features for each file in the final_df\n",
        "features_list = []\n",
        "for index, row in final_df.iterrows():\n",
        "    features = extract_features(row['File_Path'])\n",
        "    features_list.append(features)\n",
        "\n",
        "# Convert features_list to a DataFrame\n",
        "features_df = pd.DataFrame(features_list)\n",
        "\n",
        "# Add the Emotion column from final_df to features_df\n",
        "features_df['Emotion'] = final_df['Emotion']\n",
        "\n",
        "print(features_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtA_9cy5Memy",
        "outputId": "9139b5ee-72b5-4494-d3e0-15a121deceb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               0          1          2          3          4          5  \\\n",
            "0    -761.483032  71.773376  14.633630  23.550846   8.441536  18.252174   \n",
            "1    -578.749084  77.713196  -7.886116   6.420325   6.179074  11.582044   \n",
            "2    -603.779297  64.604401  -6.578300   7.780734   0.403219  11.610985   \n",
            "3    -712.075562  76.019432  12.366280  21.779139   8.561011  15.253534   \n",
            "4    -563.111694  60.146988   0.494722  13.174312   3.693977   1.640879   \n",
            "...          ...        ...        ...        ...        ...        ...   \n",
            "3595 -745.760376  59.496197  24.346766  18.837852   9.742865   5.289154   \n",
            "3596 -100.514687   9.567369  -0.561821  -1.624645  -5.292121  -3.825037   \n",
            "3597 -350.797241  23.505442  -7.981641   1.008470 -12.795454  -5.142152   \n",
            "3598 -386.030731  22.522659 -11.340427  -2.031952 -15.844463  -2.403362   \n",
            "3599 -378.480286  27.758413  -9.050571  -0.054251 -14.226600  -5.936737   \n",
            "\n",
            "             6          7          8          9  ...           153  \\\n",
            "0     0.082437  11.601342  -4.075377  -4.015073  ...  2.753450e-07   \n",
            "1    -6.712715  11.458735  -4.745236  -7.660063  ...  5.277793e-06   \n",
            "2    -9.785730   7.472545  -5.785016 -11.302113  ...  6.178083e-06   \n",
            "3    -6.755793  12.945807  -7.801950  -2.183830  ...  2.365768e-07   \n",
            "4    -8.199457  10.116116  -0.262968  -3.105442  ...  1.973677e-06   \n",
            "...        ...        ...        ...        ...  ...           ...   \n",
            "3595  7.068676   0.805551  -1.026856   0.799600  ...  5.787830e-06   \n",
            "3596 -0.625831  -0.288567  -2.763519  -4.510658  ...  1.101952e-01   \n",
            "3597 -2.108842  -2.568710  -7.269009  -9.315737  ...  2.101066e-02   \n",
            "3598 -4.301713  -4.500425 -11.750820  -4.136499  ...  5.146743e-03   \n",
            "3599 -2.682516  -2.823680  -7.578212 -10.884997  ...  9.027661e-03   \n",
            "\n",
            "               154           155           156           157           158  \\\n",
            "0     2.188259e-07  1.856785e-07  1.398019e-07  8.540421e-08  4.493517e-08   \n",
            "1     3.719302e-06  2.213509e-06  1.630029e-06  1.564844e-06  1.206530e-06   \n",
            "2     5.385103e-06  3.829471e-06  3.135173e-06  2.302947e-06  1.313578e-06   \n",
            "3     1.238775e-07  7.980262e-08  5.268634e-08  5.747041e-08  6.682298e-08   \n",
            "4     1.374965e-06  1.356757e-06  1.204481e-06  8.438928e-07  5.584820e-07   \n",
            "...            ...           ...           ...           ...           ...   \n",
            "3595  1.264498e-05  8.422355e-06  7.647433e-06  5.562451e-06  5.231389e-06   \n",
            "3596  1.319322e-01  1.450214e-01  1.495335e-01  1.479605e-01  1.276847e-01   \n",
            "3597  4.232376e-02  5.594232e-02  6.915502e-02  6.197851e-02  4.412156e-02   \n",
            "3598  8.038521e-03  9.388122e-03  1.272593e-02  1.007209e-02  1.498596e-02   \n",
            "3599  1.582482e-02  2.346549e-02  2.951812e-02  2.800748e-02  1.799247e-02   \n",
            "\n",
            "               159           160           161  Emotion  \n",
            "0     1.772313e-08  7.695315e-09  7.207385e-09      sad  \n",
            "1     8.235604e-07  1.017909e-07  8.651464e-09  fearful  \n",
            "2     4.618523e-07  4.138019e-08  8.273598e-09  fearful  \n",
            "3     3.255797e-08  9.113638e-09  7.661832e-09  neutral  \n",
            "4     3.253506e-07  4.106606e-08  8.009368e-09    angry  \n",
            "...            ...           ...           ...      ...  \n",
            "3595  6.082937e-06  3.539454e-06  3.700959e-07  neutral  \n",
            "3596  1.119864e-01  1.008163e-01  8.824328e-02    angry  \n",
            "3597  2.343016e-02  9.791063e-03  7.959013e-04    angry  \n",
            "3598  2.023338e-02  1.190898e-02  1.549095e-03    angry  \n",
            "3599  9.332476e-03  4.122147e-03  3.659953e-04    angry  \n",
            "\n",
            "[3600 rows x 163 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features data and transform it\n",
        "features_scaled = scaler.fit_transform(features_df.drop('Emotion', axis=1))\n",
        "\n",
        "# Convert the scaled features back to a DataFrame\n",
        "features_scaled_df = pd.DataFrame(features_scaled, columns=features_df.columns[:-1])\n",
        "\n",
        "# Add the Emotion column back to the scaled features DataFrame\n",
        "features_scaled_df['Emotion'] = features_df['Emotion']\n",
        "\n",
        "print(features_scaled_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P_q8d1PIBvE",
        "outputId": "ed961e42-8d5e-4070-c7ed-59cf128f2540"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6  \\\n",
            "0 -1.274558  1.185898  1.578318  2.114246  1.179709  2.369706  0.956625   \n",
            "1 -0.408729  1.413925 -0.113551  0.011961  0.895878  1.588487 -0.085357   \n",
            "2 -0.527327  0.910685 -0.015297  0.178912  0.171282  1.591877 -0.556579   \n",
            "3 -1.040456  1.348902  1.407976  1.896819  1.194698  2.018499 -0.091963   \n",
            "4 -0.334636  0.739567  0.516087  0.840821  0.584116  0.424159 -0.313337   \n",
            "\n",
            "          7         8         9  ...       153       154       155       156  \\\n",
            "0  2.555333  0.249841 -0.399751  ... -0.516611 -0.516778 -0.517168 -0.517737   \n",
            "1  2.534573  0.113431 -1.187358  ... -0.516469 -0.516679 -0.517110 -0.517695   \n",
            "2  1.954285 -0.098310 -1.974330  ... -0.516443 -0.516631 -0.517064 -0.517652   \n",
            "3  2.751052 -0.509037 -0.004057  ... -0.516612 -0.516781 -0.517171 -0.517740   \n",
            "4  2.339122  1.026198 -0.203198  ... -0.516563 -0.516745 -0.517135 -0.517707   \n",
            "\n",
            "        157       158       159       160       161  Emotion  \n",
            "0 -0.518449 -0.518987 -0.518429 -0.510961 -0.500784      sad  \n",
            "1 -0.518407 -0.518954 -0.518406 -0.510958 -0.500784  fearful  \n",
            "2 -0.518386 -0.518951 -0.518416 -0.510960 -0.500784  fearful  \n",
            "3 -0.518450 -0.518987 -0.518428 -0.510961 -0.500784  neutral  \n",
            "4 -0.518428 -0.518973 -0.518420 -0.510960 -0.500784    angry  \n",
            "\n",
            "[5 rows x 163 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow.keras import layers\n",
        "\n",
        "# # Define the neural network model\n",
        "# model = tf.keras.Sequential([\n",
        "#     layers.Dense(64, activation='relu', input_shape=(features_df.shape[1]-1,)),\n",
        "#     layers.Dense(32, activation='relu'),\n",
        "#     layers.Dense(5, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# # Compile the model\n",
        "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# # One-hot encode the Emotion column\n",
        "# emotion_labels = pd.get_dummies(features_scaled_df['Emotion']).to_numpy()\n",
        "\n",
        "# # Train the model using the entire dataset\n",
        "# model.fit(features_df.drop('Emotion', axis=1), emotion_labels, epochs=300)\n",
        "\n",
        "# # Save the model parameters\n",
        "# model.save_weights('/content/ravdess/softmax_regression_params.h5')\n",
        "#######\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Define the neural network model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Dense(128, activation='relu', input_shape=(features_df.shape[1]-1,)),\n",
        "    layers.BatchNormalization(),  # Adding batch normalization\n",
        "    layers.Dropout(0.5),  # Adding dropout for regularization\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(32, activation='relu'),\n",
        "    layers.Dense(5, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model using the entire dataset\n",
        "model.fit(features_df.drop('Emotion', axis=1), emotion_labels, epochs=300)\n",
        "\n",
        "# Save the model parameters\n",
        "model.save_weights('/content/ravdess/softmax_regression_params.h5')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0E0gOSDhoX8a",
        "outputId": "eec3af12-800c-4250-c244-b0e73937202e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "113/113 [==============================] - 2s 4ms/step - loss: 1.7764 - accuracy: 0.2633\n",
            "Epoch 2/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.5492 - accuracy: 0.3297\n",
            "Epoch 3/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.4738 - accuracy: 0.3472\n",
            "Epoch 4/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.4348 - accuracy: 0.3608\n",
            "Epoch 5/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.3985 - accuracy: 0.3731\n",
            "Epoch 6/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.3598 - accuracy: 0.3925\n",
            "Epoch 7/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.3611 - accuracy: 0.3933\n",
            "Epoch 8/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.3473 - accuracy: 0.4083\n",
            "Epoch 9/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.3313 - accuracy: 0.4047\n",
            "Epoch 10/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.3159 - accuracy: 0.4178\n",
            "Epoch 11/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.3069 - accuracy: 0.4242\n",
            "Epoch 12/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.3123 - accuracy: 0.4147\n",
            "Epoch 13/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.2840 - accuracy: 0.4192\n",
            "Epoch 14/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2709 - accuracy: 0.4303\n",
            "Epoch 15/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2708 - accuracy: 0.4283\n",
            "Epoch 16/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2696 - accuracy: 0.4506\n",
            "Epoch 17/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2685 - accuracy: 0.4469\n",
            "Epoch 18/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2720 - accuracy: 0.4464\n",
            "Epoch 19/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2584 - accuracy: 0.4414\n",
            "Epoch 20/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2575 - accuracy: 0.4369\n",
            "Epoch 21/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2546 - accuracy: 0.4458\n",
            "Epoch 22/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2345 - accuracy: 0.4594\n",
            "Epoch 23/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2549 - accuracy: 0.4422\n",
            "Epoch 24/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.2276 - accuracy: 0.4633\n",
            "Epoch 25/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.2362 - accuracy: 0.4531\n",
            "Epoch 26/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.2139 - accuracy: 0.4764\n",
            "Epoch 27/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.2241 - accuracy: 0.4569\n",
            "Epoch 28/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.2238 - accuracy: 0.4686\n",
            "Epoch 29/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.2158 - accuracy: 0.4739\n",
            "Epoch 30/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.2096 - accuracy: 0.4611\n",
            "Epoch 31/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.2222 - accuracy: 0.4658\n",
            "Epoch 32/300\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.2205 - accuracy: 0.4719\n",
            "Epoch 33/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.2116 - accuracy: 0.4594\n",
            "Epoch 34/300\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.2163 - accuracy: 0.4700\n",
            "Epoch 35/300\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.2072 - accuracy: 0.4639\n",
            "Epoch 36/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.2001 - accuracy: 0.4781\n",
            "Epoch 37/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.2177 - accuracy: 0.4814\n",
            "Epoch 38/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.2106 - accuracy: 0.4778\n",
            "Epoch 39/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1989 - accuracy: 0.4772\n",
            "Epoch 40/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1911 - accuracy: 0.4808\n",
            "Epoch 41/300\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 1.1936 - accuracy: 0.4783\n",
            "Epoch 42/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1845 - accuracy: 0.4819\n",
            "Epoch 43/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1817 - accuracy: 0.4900\n",
            "Epoch 44/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1920 - accuracy: 0.4908\n",
            "Epoch 45/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1755 - accuracy: 0.4856\n",
            "Epoch 46/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1966 - accuracy: 0.4803\n",
            "Epoch 47/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.2030 - accuracy: 0.4739\n",
            "Epoch 48/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1755 - accuracy: 0.4903\n",
            "Epoch 49/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1792 - accuracy: 0.4853\n",
            "Epoch 50/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1759 - accuracy: 0.4908\n",
            "Epoch 51/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1656 - accuracy: 0.5047\n",
            "Epoch 52/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1555 - accuracy: 0.5125\n",
            "Epoch 53/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1537 - accuracy: 0.5044\n",
            "Epoch 54/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1597 - accuracy: 0.5006\n",
            "Epoch 55/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1732 - accuracy: 0.4803\n",
            "Epoch 56/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1757 - accuracy: 0.4936\n",
            "Epoch 57/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1824 - accuracy: 0.4953\n",
            "Epoch 58/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1593 - accuracy: 0.5000\n",
            "Epoch 59/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1562 - accuracy: 0.4978\n",
            "Epoch 60/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1654 - accuracy: 0.4975\n",
            "Epoch 61/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1477 - accuracy: 0.5083\n",
            "Epoch 62/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1609 - accuracy: 0.4919\n",
            "Epoch 63/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1430 - accuracy: 0.5186\n",
            "Epoch 64/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1500 - accuracy: 0.5022\n",
            "Epoch 65/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1456 - accuracy: 0.5094\n",
            "Epoch 66/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1499 - accuracy: 0.5042\n",
            "Epoch 67/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1380 - accuracy: 0.5139\n",
            "Epoch 68/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1334 - accuracy: 0.5031\n",
            "Epoch 69/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1526 - accuracy: 0.5108\n",
            "Epoch 70/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1342 - accuracy: 0.5000\n",
            "Epoch 71/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1382 - accuracy: 0.5100\n",
            "Epoch 72/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1480 - accuracy: 0.5036\n",
            "Epoch 73/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1262 - accuracy: 0.5086\n",
            "Epoch 74/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1278 - accuracy: 0.5181\n",
            "Epoch 75/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1590 - accuracy: 0.5042\n",
            "Epoch 76/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1514 - accuracy: 0.5069\n",
            "Epoch 77/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1384 - accuracy: 0.5133\n",
            "Epoch 78/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1163 - accuracy: 0.5217\n",
            "Epoch 79/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1456 - accuracy: 0.5125\n",
            "Epoch 80/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1403 - accuracy: 0.5067\n",
            "Epoch 81/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1111 - accuracy: 0.5175\n",
            "Epoch 82/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1287 - accuracy: 0.5142\n",
            "Epoch 83/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1111 - accuracy: 0.5269\n",
            "Epoch 84/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1210 - accuracy: 0.5169\n",
            "Epoch 85/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1508 - accuracy: 0.5031\n",
            "Epoch 86/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1331 - accuracy: 0.5161\n",
            "Epoch 87/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1502 - accuracy: 0.4978\n",
            "Epoch 88/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1380 - accuracy: 0.5067\n",
            "Epoch 89/300\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.1399 - accuracy: 0.5150\n",
            "Epoch 90/300\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 1.1361 - accuracy: 0.5167\n",
            "Epoch 91/300\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 1.1364 - accuracy: 0.5064\n",
            "Epoch 92/300\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 1.1342 - accuracy: 0.5164\n",
            "Epoch 93/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1340 - accuracy: 0.5183\n",
            "Epoch 94/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1392 - accuracy: 0.5183\n",
            "Epoch 95/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1440 - accuracy: 0.5075\n",
            "Epoch 96/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1422 - accuracy: 0.5125\n",
            "Epoch 97/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1410 - accuracy: 0.5092\n",
            "Epoch 98/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1395 - accuracy: 0.5044\n",
            "Epoch 99/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1350 - accuracy: 0.5144\n",
            "Epoch 100/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1343 - accuracy: 0.5092\n",
            "Epoch 101/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1534 - accuracy: 0.4989\n",
            "Epoch 102/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1448 - accuracy: 0.5053\n",
            "Epoch 103/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1292 - accuracy: 0.5072\n",
            "Epoch 104/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1525 - accuracy: 0.5097\n",
            "Epoch 105/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1399 - accuracy: 0.5050\n",
            "Epoch 106/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1258 - accuracy: 0.5192\n",
            "Epoch 107/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1449 - accuracy: 0.5039\n",
            "Epoch 108/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1233 - accuracy: 0.5156\n",
            "Epoch 109/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1302 - accuracy: 0.5167\n",
            "Epoch 110/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1238 - accuracy: 0.5250\n",
            "Epoch 111/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1209 - accuracy: 0.5283\n",
            "Epoch 112/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1284 - accuracy: 0.5183\n",
            "Epoch 113/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1187 - accuracy: 0.5153\n",
            "Epoch 114/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1329 - accuracy: 0.5061\n",
            "Epoch 115/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1081 - accuracy: 0.5289\n",
            "Epoch 116/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1091 - accuracy: 0.5242\n",
            "Epoch 117/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1119 - accuracy: 0.5222\n",
            "Epoch 118/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1174 - accuracy: 0.5200\n",
            "Epoch 119/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1185 - accuracy: 0.5172\n",
            "Epoch 120/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1113 - accuracy: 0.5231\n",
            "Epoch 121/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1069 - accuracy: 0.5300\n",
            "Epoch 122/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1198 - accuracy: 0.5250\n",
            "Epoch 123/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1150 - accuracy: 0.5356\n",
            "Epoch 124/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1148 - accuracy: 0.5200\n",
            "Epoch 125/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1227 - accuracy: 0.5192\n",
            "Epoch 126/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1265 - accuracy: 0.5214\n",
            "Epoch 127/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1313 - accuracy: 0.5189\n",
            "Epoch 128/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1245 - accuracy: 0.5214\n",
            "Epoch 129/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1173 - accuracy: 0.5206\n",
            "Epoch 130/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1026 - accuracy: 0.5236\n",
            "Epoch 131/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1280 - accuracy: 0.5122\n",
            "Epoch 132/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1184 - accuracy: 0.5133\n",
            "Epoch 133/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1156 - accuracy: 0.5156\n",
            "Epoch 134/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1215 - accuracy: 0.5214\n",
            "Epoch 135/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1060 - accuracy: 0.5192\n",
            "Epoch 136/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1200 - accuracy: 0.5225\n",
            "Epoch 137/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1196 - accuracy: 0.5161\n",
            "Epoch 138/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1061 - accuracy: 0.5219\n",
            "Epoch 139/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1273 - accuracy: 0.5256\n",
            "Epoch 140/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1143 - accuracy: 0.5200\n",
            "Epoch 141/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1269 - accuracy: 0.5142\n",
            "Epoch 142/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1204 - accuracy: 0.5189\n",
            "Epoch 143/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1037 - accuracy: 0.5264\n",
            "Epoch 144/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0965 - accuracy: 0.5278\n",
            "Epoch 145/300\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 1.1005 - accuracy: 0.5369\n",
            "Epoch 146/300\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 1.0899 - accuracy: 0.5328\n",
            "Epoch 147/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1126 - accuracy: 0.5214\n",
            "Epoch 148/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1164 - accuracy: 0.5214\n",
            "Epoch 149/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0922 - accuracy: 0.5278\n",
            "Epoch 150/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1221 - accuracy: 0.5197\n",
            "Epoch 151/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1042 - accuracy: 0.5244\n",
            "Epoch 152/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0917 - accuracy: 0.5361\n",
            "Epoch 153/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1050 - accuracy: 0.5236\n",
            "Epoch 154/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1122 - accuracy: 0.5264\n",
            "Epoch 155/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1185 - accuracy: 0.5281\n",
            "Epoch 156/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1116 - accuracy: 0.5300\n",
            "Epoch 157/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1031 - accuracy: 0.5264\n",
            "Epoch 158/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.5194\n",
            "Epoch 159/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1049 - accuracy: 0.5353\n",
            "Epoch 160/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1079 - accuracy: 0.5300\n",
            "Epoch 161/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0921 - accuracy: 0.5286\n",
            "Epoch 162/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.5375\n",
            "Epoch 163/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1084 - accuracy: 0.5253\n",
            "Epoch 164/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0897 - accuracy: 0.5231\n",
            "Epoch 165/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0898 - accuracy: 0.5328\n",
            "Epoch 166/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0993 - accuracy: 0.5183\n",
            "Epoch 167/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1041 - accuracy: 0.5242\n",
            "Epoch 168/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1067 - accuracy: 0.5242\n",
            "Epoch 169/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1006 - accuracy: 0.5331\n",
            "Epoch 170/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1012 - accuracy: 0.5250\n",
            "Epoch 171/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0969 - accuracy: 0.5394\n",
            "Epoch 172/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0972 - accuracy: 0.5314\n",
            "Epoch 173/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1083 - accuracy: 0.5278\n",
            "Epoch 174/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0961 - accuracy: 0.5314\n",
            "Epoch 175/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0892 - accuracy: 0.5339\n",
            "Epoch 176/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0850 - accuracy: 0.5308\n",
            "Epoch 177/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1100 - accuracy: 0.5247\n",
            "Epoch 178/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0997 - accuracy: 0.5336\n",
            "Epoch 179/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0912 - accuracy: 0.5378\n",
            "Epoch 180/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1108 - accuracy: 0.5328\n",
            "Epoch 181/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1030 - accuracy: 0.5239\n",
            "Epoch 182/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0892 - accuracy: 0.5256\n",
            "Epoch 183/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0834 - accuracy: 0.5411\n",
            "Epoch 184/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0970 - accuracy: 0.5236\n",
            "Epoch 185/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0981 - accuracy: 0.5322\n",
            "Epoch 186/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0940 - accuracy: 0.5269\n",
            "Epoch 187/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1025 - accuracy: 0.5367\n",
            "Epoch 188/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1037 - accuracy: 0.5342\n",
            "Epoch 189/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0849 - accuracy: 0.5406\n",
            "Epoch 190/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1043 - accuracy: 0.5267\n",
            "Epoch 191/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0885 - accuracy: 0.5314\n",
            "Epoch 192/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0994 - accuracy: 0.5303\n",
            "Epoch 193/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0832 - accuracy: 0.5319\n",
            "Epoch 194/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0652 - accuracy: 0.5394\n",
            "Epoch 195/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0833 - accuracy: 0.5481\n",
            "Epoch 196/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0805 - accuracy: 0.5347\n",
            "Epoch 197/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0786 - accuracy: 0.5358\n",
            "Epoch 198/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1087 - accuracy: 0.5289\n",
            "Epoch 199/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0849 - accuracy: 0.5375\n",
            "Epoch 200/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0907 - accuracy: 0.5314\n",
            "Epoch 201/300\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 1.0975 - accuracy: 0.5275\n",
            "Epoch 202/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0844 - accuracy: 0.5286\n",
            "Epoch 203/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0954 - accuracy: 0.5303\n",
            "Epoch 204/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0926 - accuracy: 0.5344\n",
            "Epoch 205/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0908 - accuracy: 0.5378\n",
            "Epoch 206/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0814 - accuracy: 0.5464\n",
            "Epoch 207/300\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 1.0865 - accuracy: 0.5439\n",
            "Epoch 208/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0969 - accuracy: 0.5278\n",
            "Epoch 209/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0884 - accuracy: 0.5369\n",
            "Epoch 210/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0751 - accuracy: 0.5392\n",
            "Epoch 211/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.1069 - accuracy: 0.5233\n",
            "Epoch 212/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0785 - accuracy: 0.5406\n",
            "Epoch 213/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0867 - accuracy: 0.5272\n",
            "Epoch 214/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0758 - accuracy: 0.5486\n",
            "Epoch 215/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0833 - accuracy: 0.5467\n",
            "Epoch 216/300\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.0794 - accuracy: 0.5394\n",
            "Epoch 217/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0758 - accuracy: 0.5522\n",
            "Epoch 218/300\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.0907 - accuracy: 0.5353\n",
            "Epoch 219/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0693 - accuracy: 0.5336\n",
            "Epoch 220/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1012 - accuracy: 0.5292\n",
            "Epoch 221/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0600 - accuracy: 0.5483\n",
            "Epoch 222/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0997 - accuracy: 0.5247\n",
            "Epoch 223/300\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 1.0874 - accuracy: 0.5394\n",
            "Epoch 224/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0847 - accuracy: 0.5364\n",
            "Epoch 225/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0874 - accuracy: 0.5369\n",
            "Epoch 226/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0870 - accuracy: 0.5436\n",
            "Epoch 227/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0903 - accuracy: 0.5236\n",
            "Epoch 228/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0780 - accuracy: 0.5383\n",
            "Epoch 229/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0649 - accuracy: 0.5419\n",
            "Epoch 230/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0733 - accuracy: 0.5331\n",
            "Epoch 231/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0684 - accuracy: 0.5417\n",
            "Epoch 232/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0553 - accuracy: 0.5450\n",
            "Epoch 233/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0758 - accuracy: 0.5369\n",
            "Epoch 234/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0669 - accuracy: 0.5431\n",
            "Epoch 235/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0698 - accuracy: 0.5508\n",
            "Epoch 236/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0893 - accuracy: 0.5378\n",
            "Epoch 237/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0785 - accuracy: 0.5381\n",
            "Epoch 238/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0684 - accuracy: 0.5356\n",
            "Epoch 239/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.5397\n",
            "Epoch 240/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0842 - accuracy: 0.5297\n",
            "Epoch 241/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0971 - accuracy: 0.5375\n",
            "Epoch 242/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1007 - accuracy: 0.5347\n",
            "Epoch 243/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0700 - accuracy: 0.5425\n",
            "Epoch 244/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0644 - accuracy: 0.5456\n",
            "Epoch 245/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0818 - accuracy: 0.5328\n",
            "Epoch 246/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0779 - accuracy: 0.5475\n",
            "Epoch 247/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0870 - accuracy: 0.5342\n",
            "Epoch 248/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1059 - accuracy: 0.5267\n",
            "Epoch 249/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0859 - accuracy: 0.5392\n",
            "Epoch 250/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0850 - accuracy: 0.5300\n",
            "Epoch 251/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1009 - accuracy: 0.5308\n",
            "Epoch 252/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0966 - accuracy: 0.5372\n",
            "Epoch 253/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1104 - accuracy: 0.5272\n",
            "Epoch 254/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0840 - accuracy: 0.5400\n",
            "Epoch 255/300\n",
            "113/113 [==============================] - 1s 4ms/step - loss: 1.0955 - accuracy: 0.5336\n",
            "Epoch 256/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0802 - accuracy: 0.5431\n",
            "Epoch 257/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1047 - accuracy: 0.5300\n",
            "Epoch 258/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1020 - accuracy: 0.5222\n",
            "Epoch 259/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0834 - accuracy: 0.5442\n",
            "Epoch 260/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0949 - accuracy: 0.5272\n",
            "Epoch 261/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1041 - accuracy: 0.5228\n",
            "Epoch 262/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1046 - accuracy: 0.5347\n",
            "Epoch 263/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0937 - accuracy: 0.5375\n",
            "Epoch 264/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.1091 - accuracy: 0.5253\n",
            "Epoch 265/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0830 - accuracy: 0.5375\n",
            "Epoch 266/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0839 - accuracy: 0.5317\n",
            "Epoch 267/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0894 - accuracy: 0.5286\n",
            "Epoch 268/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.1012 - accuracy: 0.5197\n",
            "Epoch 269/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0856 - accuracy: 0.5325\n",
            "Epoch 270/300\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 1.0851 - accuracy: 0.5306\n",
            "Epoch 271/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0910 - accuracy: 0.5319\n",
            "Epoch 272/300\n",
            "113/113 [==============================] - 1s 7ms/step - loss: 1.0898 - accuracy: 0.5322\n",
            "Epoch 273/300\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 1.0881 - accuracy: 0.5375\n",
            "Epoch 274/300\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 1.0967 - accuracy: 0.5303\n",
            "Epoch 275/300\n",
            "113/113 [==============================] - 1s 10ms/step - loss: 1.0989 - accuracy: 0.5314\n",
            "Epoch 276/300\n",
            "113/113 [==============================] - 1s 11ms/step - loss: 1.0780 - accuracy: 0.5364\n",
            "Epoch 277/300\n",
            "113/113 [==============================] - 1s 9ms/step - loss: 1.0840 - accuracy: 0.5319\n",
            "Epoch 278/300\n",
            "113/113 [==============================] - 1s 8ms/step - loss: 1.0924 - accuracy: 0.5367\n",
            "Epoch 279/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1013 - accuracy: 0.5283\n",
            "Epoch 280/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0797 - accuracy: 0.5353\n",
            "Epoch 281/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.1168 - accuracy: 0.5189\n",
            "Epoch 282/300\n",
            "113/113 [==============================] - 1s 6ms/step - loss: 1.0988 - accuracy: 0.5331\n",
            "Epoch 283/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0890 - accuracy: 0.5325\n",
            "Epoch 284/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0847 - accuracy: 0.5353\n",
            "Epoch 285/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0704 - accuracy: 0.5489\n",
            "Epoch 286/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0693 - accuracy: 0.5467\n",
            "Epoch 287/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0810 - accuracy: 0.5439\n",
            "Epoch 288/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0618 - accuracy: 0.5475\n",
            "Epoch 289/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0718 - accuracy: 0.5453\n",
            "Epoch 290/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0803 - accuracy: 0.5383\n",
            "Epoch 291/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0675 - accuracy: 0.5475\n",
            "Epoch 292/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0856 - accuracy: 0.5358\n",
            "Epoch 293/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0972 - accuracy: 0.5422\n",
            "Epoch 294/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0742 - accuracy: 0.5458\n",
            "Epoch 295/300\n",
            "113/113 [==============================] - 0s 3ms/step - loss: 1.0895 - accuracy: 0.5236\n",
            "Epoch 296/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0913 - accuracy: 0.5422\n",
            "Epoch 297/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.0844 - accuracy: 0.5411\n",
            "Epoch 298/300\n",
            "113/113 [==============================] - 0s 4ms/step - loss: 1.1121 - accuracy: 0.5322\n",
            "Epoch 299/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0866 - accuracy: 0.5369\n",
            "Epoch 300/300\n",
            "113/113 [==============================] - 1s 5ms/step - loss: 1.0780 - accuracy: 0.5419\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **TESTING**"
      ],
      "metadata": {
        "id": "QoD8-RAk7zz0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-XtJwrnWB8DZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_set_list = os.listdir(test_set_path)\n",
        "\n",
        "test_data = []\n",
        "\n",
        "for dir in test_set_list:\n",
        "  actor = os.listdir(test_set_path+ '/'+ dir)\n",
        "  for file in actor:\n",
        "    part = file.split('.')[0]\n",
        "    part = part.split('-')\n",
        "    emotion = emotions.get(part[2], None)\n",
        "    if emotion is not None and emotion in observed_emotions:\n",
        "      file_path = os.path.join(test_set_path, dir, file)\n",
        "      test_data.append({'Emotion': emotion, 'File_Path': file_path})\n",
        "\n",
        "test_ravdess_df = pd.DataFrame(test_data)"
      ],
      "metadata": {
        "id": "N5f0NsDx1q3r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_features_list = []\n",
        "for index, row in test_ravdess_df.iterrows():\n",
        "    features = extract_features(row['File_Path'])\n",
        "    test_features_list.append(features)\n",
        "\n",
        "# Convert features_list to a DataFrame\n",
        "test_features_df = pd.DataFrame(test_features_list)\n",
        "\n",
        "# Add the Emotion column from final_df to features_df\n",
        "test_features_df['Emotion'] = test_ravdess_df['Emotion']"
      ],
      "metadata": {
        "id": "y7Ot6-KZ8oZO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_emotion_labels = pd.get_dummies(test_features_df['Emotion']).to_numpy()\n",
        "test_features_df_modified = test_features_df.drop('Emotion', axis=1)"
      ],
      "metadata": {
        "id": "KqqRxKLO_X4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Create a StandardScaler object\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler to the features data and transform it\n",
        "test_features_scaled = scaler.fit_transform(test_features_df.drop('Emotion', axis=1))\n",
        "\n",
        "# Convert the scaled features back to a DataFrame\n",
        "test_features_scaled_df = pd.DataFrame(test_features_scaled, columns=test_features_df.columns[:-1])\n",
        "\n",
        "# Add the Emotion column back to the scaled features DataFrame\n",
        "test_features_scaled_df['Emotion'] = test_features_df['Emotion']\n",
        "\n",
        "print(test_features_scaled_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ANVkEJpIWld",
        "outputId": "5cf9ba7e-fff7-4f96-c602-88e877b04160"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0         1         2         3         4         5         6  \\\n",
            "0 -1.424114 -0.199530  0.512823 -0.368760 -0.433681 -1.199255  0.169433   \n",
            "1  0.363747 -1.312970 -0.616007  0.305981 -1.258350 -1.271668 -0.142840   \n",
            "2 -0.131468  0.131952  0.225756  0.862263 -0.624877 -0.774208 -0.632564   \n",
            "3  0.333710 -0.299634 -1.493054 -0.480367 -0.201335 -1.220007 -2.495999   \n",
            "4  0.852609 -1.159578 -1.422847  0.200169 -1.312053 -2.189700 -1.010546   \n",
            "\n",
            "          7         8         9  ...       153       154       155       156  \\\n",
            "0 -0.369657 -1.054612 -0.131097  ... -0.605555 -0.600779 -0.600837 -0.577673   \n",
            "1  0.061911 -1.096982  0.349940  ...  3.162275  2.229686  2.297152  2.986351   \n",
            "2 -1.232867 -1.904443 -2.176419  ...  0.256370  0.594445  0.932813  0.965304   \n",
            "3  0.200761 -0.252066 -0.225311  ... -0.331917 -0.306999 -0.283264 -0.330740   \n",
            "4  0.319586 -0.753594 -0.552446  ...  1.199173  1.083483  1.216885  1.536872   \n",
            "\n",
            "        157       158       159       160       161  Emotion  \n",
            "0 -0.551511 -0.533991 -0.533666 -0.515764 -1.077003  neutral  \n",
            "1  3.666498  3.495352  2.770149  2.671633  1.400629  fearful  \n",
            "2  0.542215  0.387916  0.027105 -0.059666  1.047484      sad  \n",
            "3 -0.322973 -0.275734 -0.303459 -0.322818  0.343273    happy  \n",
            "4  1.396984  0.820024  0.768864  0.531175  0.809136    angry  \n",
            "\n",
            "[5 rows x 163 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def test_model(test_features_df_modified, test_emotion_labels):\n",
        "    # Load the saved model parameters\n",
        "    model.load_weights('/content/ravdess/softmax_regression_params.h5')\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred = model.predict(test_features_df_modified)\n",
        "\n",
        "    # Convert predictions to class labels\n",
        "    y_pred_class = np.argmax(y_pred, axis=1)\n",
        "\n",
        "    # Calculate accuracy\n",
        "    accuracy = accuracy_score(np.argmax(test_emotion_labels, axis=1), y_pred_class)\n",
        "\n",
        "    # Print accuracy in percentage\n",
        "    print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Call the function\n",
        "test_model(test_features_df_modified, test_emotion_labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5UiwCH7_amf",
        "outputId": "6ad715ac-039b-4e6c-8b6a-408d971c43a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 4ms/step\n",
            "Accuracy: 54.86%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import logging\n",
        "\n",
        "# Initialize logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "def load_model_weights(model, filepath: str):\n",
        "    try:\n",
        "        model.load_weights(filepath)\n",
        "        logging.info(\"Model weights loaded successfully.\")\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to load model weights: {e}\")\n",
        "        raise\n",
        "\n",
        "def predict_labels(model, features: np.ndarray) -> np.ndarray:\n",
        "    try:\n",
        "        predictions = model.predict(features)\n",
        "        predicted_classes = np.argmax(predictions, axis=1)\n",
        "        logging.info(\"Predictions made successfully.\")\n",
        "        return predicted_classes\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Prediction failed: {e}\")\n",
        "        raise\n",
        "\n",
        "def calculate_metrics(true_labels: np.ndarray, predicted_labels: np.ndarray):\n",
        "    try:\n",
        "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "        precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "        recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "        f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
        "\n",
        "        # Logging the results\n",
        "        logging.info(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "        logging.info(f\"Precision: {precision * 100:.2f}%\")\n",
        "        logging.info(f\"Recall: {recall * 100:.2f}%\")\n",
        "        logging.info(f\"F1 Score: {f1 * 100:.2f}%\")\n",
        "\n",
        "        # Printing the results\n",
        "        print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "        print(f\"Precision: {precision * 100:.2f}%\")\n",
        "        print(f\"Recall: {recall * 100:.2f}%\")\n",
        "        print(f\"F1 Score: {f1 * 100:.2f}%\")\n",
        "\n",
        "        return accuracy, precision, recall, f1\n",
        "    except Exception as e:\n",
        "        logging.error(f\"Failed to calculate metrics: {e}\")\n",
        "        raise\n",
        "\n",
        "def test_model(model, test_features_df_modified: np.ndarray, test_emotion_labels: np.ndarray, weights_filepath: str):\n",
        "    \"\"\"\n",
        "    Test the model with the provided features and labels.\n",
        "\n",
        "    Parameters:\n",
        "    model: The machine learning model to be tested.\n",
        "    test_features_df_modified (np.ndarray): Modified test features.\n",
        "    test_emotion_labels (np.ndarray): True emotion labels for the test data.\n",
        "    weights_filepath (str): Path to the saved model weights.\n",
        "\n",
        "    Returns:\n",
        "    tuple: Accuracy, precision, recall, and F1 score of the model on the test data.\n",
        "    \"\"\"\n",
        "    # Load the saved model parameters\n",
        "    load_model_weights(model, weights_filepath)\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    y_pred_class = predict_labels(model, test_features_df_modified)\n",
        "\n",
        "    # Calculate and return metrics\n",
        "    return calculate_metrics(np.argmax(test_emotion_labels, axis=1), y_pred_class)\n",
        "\n",
        "# Example call to the function\n",
        "# Assuming 'model', 'test_features_df_modified', 'test_emotion_labels', and 'weights_filepath' are defined\n",
        "accuracy, precision, recall, f1 = test_model(model, test_features_df_modified, test_emotion_labels, '/content/ravdess/softmax_regression_params.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxgnPITgCfTA",
        "outputId": "dc828113-18e7-4df2-9e29-7a84fb86dede"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 5ms/step\n",
            "Accuracy: 54.86%\n",
            "Precision: 53.46%\n",
            "Recall: 54.86%\n",
            "F1 Score: 53.34%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQPlGb08I2Qi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}